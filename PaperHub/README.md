# PaperHub - Personal Academic Paper Management and Recommendation System(ä¸ªäººå­¦æœ¯è®ºæ–‡ç®¡ç†ä¸æ¨èç³»ç»Ÿ)

An intelligent paper management system built on Python + FastAPI + PostgreSQL + Streamlit, supporting batch import of arXiv papers, semantic search, and personalized recommendations.

## æ ¸å¿ƒåŠŸèƒ½

- **æ‰¹é‡å¯¼å…¥**ï¼šæ”¯æŒä» arXiv æŒ‰å…³é”®è¯æˆ–åˆ†ç±»æ‰¹é‡å¯¼å…¥è®ºæ–‡
- **æ™ºèƒ½æœç´¢**ï¼šåŸºäºæ ‡é¢˜ã€æ‘˜è¦ã€æ ‡ç­¾ã€ç±»åˆ«ç­‰å¤šç»´åº¦æœç´¢
- **æ™ºèƒ½æ¨è**ï¼š
  - åŸºäº sentence-transformers çš„è¯­ä¹‰ç›¸ä¼¼åº¦æ¨è
  - ä¸ªæ€§åŒ–æ¨èï¼ˆåŸºäºé˜…è¯»å†å²ï¼‰
  - æ··åˆæ¨èç­–ç•¥
- **æ ‡ç­¾ç®¡ç†**ï¼šå¤šå¯¹å¤šæ ‡ç­¾ç³»ç»Ÿï¼Œçµæ´»åˆ†ç±»
- **ç»Ÿè®¡åˆ†æ**ï¼šè®ºæ–‡åˆ†å¸ƒã€é˜…è¯»è®°å½•ç­‰å¯è§†åŒ–ç»Ÿè®¡
- **å‘é‡å­˜å‚¨**ï¼šä½¿ç”¨ pgvector å­˜å‚¨å’Œæ£€ç´¢ 384 ç»´è¯­ä¹‰å‘é‡

## Core Features

- **Batch Import**: Supports bulk import of papers from arXiv by keywords or categories
- **Intelligent Search**: Multi-dimensional search based on title, abstract, tags, categories, and more
- **Intelligent Recommendations**:
  - Semantic similarity recommendations based on sentence-transformers
  - Personalized recommendations (based on reading history)
  - Hybrid recommendation strategies
- **Tag Management**: Many-to-many tag system for flexible categorization
- **Statistical Analysis**: Visualized statistics on paper distribution, reading records, and more
- **Vector Storage**: Uses pgvector to store and retrieve 384-dimensional semantic vectors

## æŠ€æœ¯æ ˆ

- **åç«¯æ¡†æ¶**ï¼šFastAPI
- **å‰ç«¯ç•Œé¢**ï¼šStreamlit
- **æ•°æ®åº“**ï¼šPostgreSQL + pgvector
- **ORM**ï¼šSQLAlchemy 2.0
- **æ¨èå¼•æ“**ï¼šsentence-transformers (all-MiniLM-L6-v2)
- **è®ºæ–‡æ•°æ®æº**ï¼šarXiv API
- **å®¹å™¨åŒ–**ï¼šDocker Compose

## Technology Stack

- **Backend Framework**: FastAPI
- **Frontend Interface**: Streamlit
- **Database**: PostgreSQL + pgvector
- **ORM**: SQLAlchemy 2.0
- **Recommendation Engine**: sentence-transformers (all-MiniLM-L6-v2)
- **Paper Data Source**: arXiv API
- **Containerization**: Docker Compose

## é¡¹ç›®ç»“æ„

```
PaperHub/
â”‚
â”œâ”€â”€ app/                          # ä¸»åº”ç”¨ç›®å½•
â”‚   â”œâ”€â”€ __init__.py              # Python åŒ…åˆå§‹åŒ–
|   |
â”‚   â”œâ”€â”€ main.py                  # Streamlit ä¸»ç¨‹åº
â”‚   â”‚
â”‚   â”œâ”€â”€ database.py              # æ•°æ®åº“é…ç½®
â”‚   â”‚
â”‚   â”œâ”€â”€ models.py                # ORM æ¨¡å‹
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas.py               # Pydantic éªŒè¯æ¨¡å‹
â”‚   â”‚
â”‚   â”œâ”€â”€ crud.py                  # æ•°æ®åº“æ“ä½œ
â”‚   â”‚
â”‚   â”œâ”€â”€ recommender.py           # æ¨èå¼•æ“
â”‚   â”‚
â”‚   â””â”€â”€ utils.py                 # å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ .env                         # ç¯å¢ƒå˜é‡ï¼ˆç”Ÿäº§é…ç½®ï¼‰
â”œâ”€â”€ .env.example                 # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ .gitignore                   # Git å¿½ç•¥è§„åˆ™
â”‚
â”œâ”€â”€ docker-compose.yml           # Docker ç¼–æ’æ–‡ä»¶
â”‚
â”œâ”€â”€ init.sql                     # æ•°æ®åº“åˆå§‹åŒ– SQL
â”‚
â”œâ”€â”€ requirements.txt             # Python ä¾èµ–æ¸…å•
â”‚
â”œâ”€â”€ start.bat                    # Windows å¯åŠ¨è„šæœ¬
â”‚
â”œâ”€â”€ README.md                    # å®Œæ•´é¡¹ç›®æ–‡æ¡£
â”‚
â”œâ”€â”€ QUICKSTART.md                # å¿«é€Ÿå¼€å§‹æŒ‡å—
â”‚
â””â”€â”€ PROJECT_OVERVIEW.md          # é¡¹ç›®æ¦‚è§ˆ
```

## Project Structure

```
PaperHub/
â”‚
â”œâ”€â”€ app/                          # Main application directory
â”‚   â”œâ”€â”€ __init__.py              # Python package initialization
|   |  
â”‚   â”œâ”€â”€ main.py                  # Streamlit main program
â”‚   â”‚
â”‚   â”œâ”€â”€ database.py              # Database configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ models.py                # ORM models
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas.py               # Pydantic validation models
â”‚   â”‚
â”‚   â”œâ”€â”€ crud.py                  # Database operations
â”‚   â”‚
â”‚   â”œâ”€â”€ recommender.py           # Recommendation engine
â”‚   â”‚
â”‚   â””â”€â”€ utils.py                 # Utility functions
â”‚
â”œâ”€â”€ .env                         # Environment variables (production configuration)
â”œâ”€â”€ .env.example                 # Environment variable template
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ docker-compose.yml           # Docker orchestration file
â”‚
â”œâ”€â”€ init.sql                     # Database initialization SQL
â”‚
â”œâ”€â”€ requirements.txt             # Python dependency list
â”‚
â”œâ”€â”€ start.bat                    # Windows startup script
â”‚
â”œâ”€â”€ README.md                    # Complete project documentation
â”‚
â”œâ”€â”€ QUICKSTART.md                # Quick start guide
â”‚
â””â”€â”€ PROJECT_OVERVIEW.md          # Project overview
```

## Quick Start

### 1. Environment Preparation

Ensure the following software is installedï¼š
- Python 3.9+
- Docker Desktop
- Git

### 2. Clone the project

```bash
git clone <your-repo-url>
cd PaperHub
```

### 3. Configure environment variables

```bash
copy .env.example .env
```

`.env` Examples of file contentsï¼š
```env
DATABASE_URL=postgresql://paperhub:paperhub123@localhost:5432/paperhub
POSTGRES_USER=paperhub
POSTGRES_PASSWORD=paperhub123
POSTGRES_DB=paperhub
```

### 4. Start the database

Start PostgreSQL (with pgvector extension) using Docker Compose:

```bash
docker-compose up -d
```

Wait for the database to start (approximately 10-20 seconds). 
You can check the status with the following command:

```bash
docker-compose ps
```

### 5. Install Python dependencies

```bash
pip install -r requirements.txt
```

### 6. Initialize the database

```bash
python -m app.database
```

you can seeï¼š`æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸï¼`

### 7. Start the application

```bash
python -m streamlit run app/main.py
```

## User Guide

### Import Papers

1. Navigate to the **ğŸ“¥ Import Papers** page
2. Select an import method:
   - **Keyword Search**: Enter keywords (e.g., "deep learning") to search arXiv
   - **Category Browsing**: Select arXiv categories (e.g., cs.AI, cs.CV) to retrieve papers in bulk
3. Click **â• Import** to add papers to the database (embeddings are generated automatically)

### Browse and Search

1. View all papers on the **ğŸ  Home** page
2. Use the search box to enter keywords (searches titles and abstracts)
3. Filter by categories and tags
4. Enable date filtering to view papers from a specific time range

### Intelligent Recommendations

1. When viewing **paper details**, the system automatically recommends similar papers
2. Navigate to the **ğŸ¯ Recommendations** page:
   - **Based on Reading History**: Get recommendations related to papers you've read
   - **Based on Current Paper**: Select a paper to find similar research

### Tag Management

1. Navigate to the **ğŸ·ï¸ Tag Management** page
2. Create new tags or view existing ones
3. Check the number of papers associated with each tag

### Statistics

Navigate to the **ğŸ“Š Statistics page** to view:
- Total number of papers, tags, and read papers
- Distribution of papers across categories
- Recently imported papers

## Database Models

### Paper
- `id`: Primary Key
- `title`: title of paper
- `authors`: list of authorsï¼ˆJSONï¼‰
- `abstract`: abstract
- `pdf_url`: PDF download link
- `arxiv_id`: arXiv ID
- `category`: category
- `published_date`: published date
- `embedding`: 384-dimensional semantic vectorï¼ˆpgvectorï¼‰

### Tag
- `id`: Primary Key
- `name`: name of tag
- `description`: description

### PaperTag
- n to m

### ReadingHistory
- `id`: Primary Key
- `paper_id`: ID of paper
- `user_id`: ID of user
- `read_at`: time of reading
- `rating`: (1 to 5)
- `notes`: notes

## Recommendation Algorithm

### 1. Content-Based Recommendation

using `sentence-transformers/all-MiniLM-L6-v2` modelï¼š
- inputï¼štitle and abstract
- outputï¼š384-dimensional semantic vector
- Similarity calculation: Cosine similarity (pgvector <=> operator)

### 2. Reading History-Based Recommendation

- Retrieve the N most recently read papers by the user
- Calculate the average embedding of these papers
- Find papers most similar to the average vector (excluding those already read)

### 3. Hybrid Recommendation

- Combine current paper and user history:
- Current paper embedding: 70%
- Historical average embedding: 30%

## Configuration Instructions

### Environment Variables

| Variables | Description | Default Value |
|--------|------|--------|
| `DATABASE_URL` | PostgreSQL linking URL | `postgresql://postgres:123456@localhost:5432/postgres` |
| `EMBEDDING_MODEL` | sentence-transformers model name | `sentence-transformers/all-MiniLM-L6-v2` |
| `EMBEDDING_DIMENSION` | dimensional semantic vector | `384` |
| `ARXIV_MAX_RESULTS` | the max number of arXiv search | `50` |

### Database configuration

Default configuration (can be modified in docker-compose.yml):
- userï¼š`paperhub`
- passwordï¼š`paperhub123`
- DBï¼š`paperhub`
- localhostï¼š`5432`

## Extension Suggestions

- [ ] User Authentication System (Supports Multiple Users)
- [ ] PDF Text Extraction and Full-Text Search
- [ ] Notes and Annotation Features
- [ ] Paper Citation Relationship Graph
- [ ] Email Subscription (Regular Recommendations)
- [ ] RESTful APIï¼ˆFastAPIï¼‰
- [ ] Export Functionality (BibTeX, Markdown)
